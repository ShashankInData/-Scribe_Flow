# ğŸ™ ScribeFlow â€” Speech to Structured Text

ScribeFlow is a **Streamlit** app that transcribes audio/video, can optionally separate speakers (diarization), and exports results to **SRT, VTT, DOCX, and PDF**.  
It also offers an **AI-generated summary** of the transcript.

---

## âœ¨ Features

- ğŸµ **Multi-format upload**: MP3, WAV, M4A, MP4, MOV, AVI, FLAC, OGG
- ğŸ“º **YouTube URL support** (via `yt-dlp`)
- ğŸ¤– **OpenAI Whisper transcription** (`gpt-4o-mini-transcribe`)
- ğŸ—£ï¸ **Optional speaker diarization** (`pyannote.audio 3.1+`)
- ğŸ·ï¸ **Speaker rename UI** when multiple speakers are detected
- ğŸ“‚ **Exports**: SRT, WebVTT, DOCX, PDF
- ğŸ“œ **AI summary** (OpenAI GPT)

---

## ğŸ“‚ Project Structure

Scribe_Flow/
â”œâ”€ app.py
â”œâ”€ backend/
â”‚ â”œâ”€ asr.py # Transcription + chunking + optional diarization mapping
â”‚ â”œâ”€ diarization.py # pyannote.audio 3.1 pipeline wrapper (GPU-aware)
â”‚ â”œâ”€ exports.py # SRT/VTT/DOCX/PDF exporters (DOCX/PDF return bytes)
â”‚ â”œâ”€ ai_tools.py # AI summary (and optional extensions)
â”‚ â””â”€ utils.py # ffmpeg, yt-dlp, file helpers, duration
â”œâ”€ data/
â”‚ â”œâ”€ uploads/
â”‚ â””â”€ outputs/
â”œâ”€ .env.example
â”œâ”€ requirements.txt
â””â”€ README.md

---

## ğŸ“‹ Requirements

- Python **3.11+**
- **FFmpeg** installed and on PATH
- **OpenAI API key**
- (Optional) Hugging Face access token for diarization

---

## ğŸš€ Setup

```bash
# Clone the repository
git clone https://github.com/ShashankInData/-Scribe_Flow.git
cd -Scribe_Flow

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows
.\.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

âš™ï¸ Configuration
Create your .env file
# Windows (PowerShell)
copy .env.example .env

# macOS/Linux
cp .env.example .env

Edit .env and set your API keys:
OPENAI_API_KEY=your_openai_key_here
# Optional for diarization:
HUGGINGFACE_TOKEN=your_hf_token_here
# Optional tuning:
ASR_CONCURRENCY=3

â–¶ï¸ Run the App
streamlit run app.py

In the sidebar:

Paste your OpenAI API key

Toggle "Enable speaker diarization" if your audio has multiple speakers
(A rename UI will appear if â‰¥2 speakers are detected)


ğŸ“– Usage
Upload a local media file or paste a YouTube URL

Click Transcribe

View results:

Transcript (full text)

Timed Segments (with optional speaker rename)

Export in SRT, VTT, DOCX, or PDF

Use the AI Summary feature for a concise recap

ğŸ“Œ Notes on Large Files
Very large uploads are memory-heavy in Streamlit

Prefer YouTube URL for long content

For local large files, consider pre-downloading with yt-dlp into data/uploads/

âš¡ GPU & Diarization
Diarization (pyannote.audio 3.1) runs on CPU by default

Switches to GPU if CUDA is available

Install PyTorch with CUDA for acceleration

ğŸ›  Troubleshooting
DOCX/PDF unreadable â†’ Ensure backend/exports.py returns bytes (âœ… fixed in this version)

FFmpeg not found â†’ Install FFmpeg and ensure itâ€™s on PATH (ffmpeg -version should work)

OpenAI 404/model errors â†’ Verify model gpt-4o-mini-transcribe and API key

Diarization not working â†’ Check HUGGINGFACE_TOKEN and model terms acceptance on Hugging Face

ğŸ—º Roadmap
AI: Action items & highlights

Chapters for long media

Quotes extraction / post writer / quiz generator

Resumable uploads for very large files

ğŸ“œ License
MIT License
